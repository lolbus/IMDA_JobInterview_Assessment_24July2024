{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a3157995-4be5-440f-9227-3506caeab65f",
   "metadata": {},
   "source": [
    "(B) Deliverable  \r\n",
    "1 \tREADME.md \r",
    "2\tPython code (use the following template and feel free to add the necessary methods)\r\n",
    "class Captcha(object):\r\n",
    "    def __init__(self):\r\n",
    "        pass\r\n",
    "\r\n",
    "    def __call__(self, im_path, save_path):\r\n",
    "        \"\"\"\r\n",
    "        Algo for inference\r\n",
    "        args:\r\n",
    "            im_path: .jpg image path to load and to infer\r\n",
    "            save_path: output file path to save the one-line outcome\r\n",
    "        \"\"\"\r\n",
    "        pass\r\n",
    "We would like to learn more about the way you frame the problem and formulate the solution. You may check in the deliverables to your Github or Gitlab and share with us the link.\r\n",
    "b and share with us the link.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6136ecb-65e6-4467-8a2c-901db5ff33bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample usage of OpenAI trained torch model\n",
    "import OpenAIInferenceEngine\n",
    "from OpenAIInferenceEngine import load_OpenAI_ai_model, llm_model\n",
    "from InferenceDataloader import dataloader\n",
    "from PIL import Image\n",
    "\n",
    "openai_api_key = \"sk-proj-OP2IckZNWS1a9GsDQLYzT3BlbkFJkQ3fVVD3BpJw4cG8b6Yv\"\n",
    "\n",
    "\n",
    "# Use data used for zero-shot prompting to fine-tune LLM\n",
    "finetune_input_dir = r\"C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\fine-tune-data\\input\"\n",
    "finetune_output_dir = r\"C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\fine-tune-data\\output\"\n",
    "training_data = dataloader(input_dir = finetune_input_dir, output_dir = finetune_output_dir)\n",
    "OpenAIInferenceEngine.llm_agent = llm_model(finetune = False, training_data = training_data, openai_api_key=openai_api_key)\n",
    "openai_ai_model = load_OpenAI_ai_model()\n",
    "\n",
    "\n",
    "sample_catpcha_image_path = r'C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\sampleCaptchas\\input\\input19.jpg'\n",
    "\n",
    "ir = openai_ai_model.get_image_information(sample_catpcha_image_path)\n",
    "print(ir)\n",
    "\n",
    "sample_image = Image.open(sample_catpcha_image_path)\n",
    "display(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5accc6b-2eee-4efb-878d-b8a2e6bed2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample usage of torch trained torch model\n",
    "from TorchInferenceEngine import load_torch_ai_model\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "torch_ai_model = load_torch_ai_model(model_path = 'imda_technical_test_pytorch_model.pth')\n",
    "sample_catpcha_image_path = r'C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\sampleCaptchas\\input\\input19.jpg'\n",
    "ir = torch_ai_model.get_image_information(sample_catpcha_image_path)\n",
    "print(ir)\n",
    "\n",
    "sample_image = Image.open(sample_catpcha_image_path)\n",
    "display(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bffed5-41ea-4dd6-ba0e-6ca0ca1a87bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample usage of Pytorch + OpenAI Gpt4o Collaboration model\n",
    "import OpenAIInferenceEngine\n",
    "from OpenAIInferenceEngine import load_OpenAI_ai_model, llm_model\n",
    "from InferenceDataloader import dataloader\n",
    "from TorchInferenceEngine import load_torch_ai_model\n",
    "from CollaborativeInferenceEngine import load_collaborative_model\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "openai_api_key = \"sk-proj-OP2IckZNWS1a9GsDQLYzT3BlbkFJkQ3fVVD3BpJw4cG8b6Yv\"\n",
    "\n",
    "# Insert OpenAI API Keys into LLM\n",
    "OpenAIInferenceEngine.llm_agent = llm_model(openai_api_key=openai_api_key)\n",
    "\n",
    "# define the models\n",
    "openai_ai_model = load_OpenAI_ai_model()\n",
    "torch_ai_model = load_torch_ai_model(model_path = 'imda_technical_test_pytorch_model.pth')\n",
    "        \n",
    "collaborative_model = load_collaborative_model(torch_ai_model=torch_ai_model, openai_ai_model=openai_ai_model)\n",
    "sample_catpcha_image_path = r'C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\sampleCaptchas\\input\\input19.jpg'\n",
    "ir = collaborative_model.get_image_information(sample_catpcha_image_path)\n",
    "print(ir)\n",
    "\n",
    "sample_image = Image.open(sample_catpcha_image_path)\n",
    "display(sample_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69881003-b276-4223-b7d2-bb85d6731e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62776d59-5537-4322-acc2-ec9b507fe2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Available Strategies:\n",
    "1. OpenAI GPT4o AI Assistant - LLMAIAssistant\n",
    "2. PyTorch self trained model - PytorchCNN\n",
    "3. Pytorch + OpenAI GPT4o AI Assistant Collaboration - LLMAIAssistant+PytorchCNN\"\"\"\n",
    "openai_api_key = \"sk-proj-OP2IckZNWS1a9GsDQLYzT3BlbkFJkQ3fVVD3BpJw4cG8b6Yv\"\n",
    "\n",
    "class Captcha(object):\n",
    "    def __init__(self, strategy = \"\"):\n",
    "        if strategy == \"LLMAIAssistant\":\n",
    "            import OpenAIInferenceEngine\n",
    "            from OpenAIInferenceEngine import load_OpenAI_ai_model, llm_model\n",
    "            from InferenceDataloader import dataloader\n",
    "            # Use data used for zero-shot prompting to fine-tune LLM\n",
    "            finetune_input_dir = r\"C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\fine-tune-data\\input\"\n",
    "            finetune_output_dir = r\"C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\fine-tune-data\\output\"\n",
    "            training_data = dataloader(input_dir = finetune_input_dir, output_dir = finetune_output_dir)\n",
    "            OpenAIInferenceEngine.llm_agent = llm_model(finetune = False, training_data = training_data, openai_api_key=openai_api_key)\n",
    "            self.openai_ai_model = load_OpenAI_ai_model()\n",
    "            self.caller = self.openai_ai_model.get_image_information\n",
    "        elif strategy == \"PytorchCNN\":\n",
    "            from TorchInferenceEngine import load_torch_ai_model\n",
    "            self.torch_ai_model = load_torch_ai_model(model_path = 'imda_technical_test_pytorch_model.pth')\n",
    "            self.caller = self.torch_ai_model.get_image_information\n",
    "        else:\n",
    "            print(f\"{strategy} is not a valid method\")\n",
    "\n",
    "    def __call__(self, im_path, save_path):\n",
    "        \"\"\"\n",
    "        Algo for inference\n",
    "        args:\n",
    "            im_path: .jpg image path to load and to infer\n",
    "            save_path: output file path to save the one-line outcome\n",
    "        \"\"\"\n",
    "        result = self.caller(im_path)\n",
    "        return result\n",
    "captcha_inferencer = Captcha(strategy = \"LLMAIAssistant\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9715e9-0ce7-4fdd-be9b-69d1a17eb4b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from InferenceDataloader import dataloader\n",
    "from PIL import Image\n",
    "\n",
    "input_dir = r\"C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\sampleCaptchas\\input\"\n",
    "output_dir = r\"C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\sampleCaptchas\\output\"\n",
    "\n",
    "inference_data = dataloader(input_dir, output_dir)\n",
    "\n",
    "corrects = 0\n",
    "attempts = 0\n",
    "for data_path in inference_data.data_dict:\n",
    "    displayable_image = Image.open(data_path)\n",
    "    display(displayable_image)\n",
    "\n",
    "    true_label = inference_data.data_dict[data_path]\n",
    "    inferred_output = captcha_inferencer(data_path, None)\n",
    "    predict = inferred_output['InferredCharacters']\n",
    "    print(f\"Predict result: {predict} versus True Label: {true_label}\")\n",
    "    if predict == true_label:\n",
    "        corrects += 1\n",
    "    else:\n",
    "        print(\"incorrect! Predicting\", data_path)\n",
    "    attempts += 1\n",
    "    print()\n",
    "\n",
    "print(f\"Final remarks: corrects {corrects} out of {attempts} attempts. accuracy of {corrects/attempts:.2f}\")\n",
    "\n",
    "\n",
    "# Common errors, mistaken O as 0, I mistake as 1, mistake 0 as O, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce7d06d-91d8-4b4e-af98-493567af64aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f14a5a-6314-4f6b-8cab-777d2b655479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

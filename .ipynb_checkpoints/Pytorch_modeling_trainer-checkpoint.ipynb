{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d1eb9df-0cd1-4bff-9ad3-c21964af42ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.6465]), Std: tensor([0.4210])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import numpy as np\n",
    "import random\n",
    "from SimpleCNN import SimpleCNNArchitecture\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set the seed\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "\n",
    "# Directories\n",
    "image_dir = r'C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\torch_training_data\\letters\\input'\n",
    "label_dir = r'C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\torch_training_data\\letters\\output'\n",
    "\n",
    "# Custom Dataset\n",
    "class CharacterDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = glob.glob(os.path.join(image_dir, '*.jpg'))\n",
    "        self.label_files = glob.glob(os.path.join(label_dir, '*.txt'))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        label_path = os.path.join(self.label_dir, os.path.basename(img_path.replace(\"in\", \"out\")).replace('.jpg', '.txt'))\n",
    "        \n",
    "        image = Image.open(img_path).convert('L')  # Convert image to grayscale\n",
    "        with open(label_path, 'r') as f:\n",
    "            label = f.read().strip()\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = ord(label) - ord('A') if 'A' <= label <= 'Z' else ord(label) - ord('0') + 26\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Function to compute mean and std\n",
    "def compute_mean_std(dataset):\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    for images, _ in loader:\n",
    "        batch_samples = images.size(0)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "        total_samples += batch_samples\n",
    "\n",
    "    mean /= total_samples\n",
    "    std /= total_samples\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "# Create a dataset without normalization to compute mean and std\n",
    "dataset = CharacterDataset(image_dir, label_dir, transform=transforms.ToTensor())\n",
    "mean, std = compute_mean_std(dataset)\n",
    "print(f\"Mean: {mean}, Std: {std}\")\n",
    "\n",
    "\n",
    "# Data transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "# Create dataset\n",
    "dataset = CharacterDataset(image_dir, label_dir, transform=transform)\n",
    "\n",
    "# Perform train/validation/test split\n",
    "train_size = int(0.6 * len(dataset))\n",
    "validation_size = len(dataset) - train_size\n",
    "train_dataset, validation_dataset = random_split(dataset, [train_size, validation_size])\n",
    "\n",
    "# Data loaders\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# validation_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Model, loss function, optimizer\n",
    "model = SimpleCNNArchitecture()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learn_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learn_rate)\n",
    "\n",
    "# Lambda function for the scheduler\n",
    "def lr_lambda(epoch):\n",
    "    return max(1 - epoch / 300, 0.01)\n",
    "\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    best_val_acc = 0.0\n",
    "    best_model = copy.deepcopy(model)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        # Step the scheduler\n",
    "        if scheduler != None:\n",
    "            scheduler.step()\n",
    "        epoch_loss = running_loss\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss = val_loss \n",
    "        val_accuracy = correct / total\n",
    "        if val_accuracy > best_val_acc:\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_val_acc = val_accuracy\n",
    "            print(\"!!!NEW BEST VAL ACC\", best_val_acc)\n",
    "            print()\n",
    "        print(f'Current Best Val Acc: {best_val_acc:.4f} Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "    best_model.eval()\n",
    "    return best_model\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    # Assuming 'model' is your trained model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53a8d0b7-086e-40ab-bb0a-7a83e14c962c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300, Loss: 260.1778\n",
      "!!!NEW BEST VAL ACC 0.041666666666666664\n",
      "\n",
      "Current Best Val Acc: 0.0417 Validation Loss: 172.3686, Validation Accuracy: 0.0417\n",
      "Epoch 2/300, Loss: 251.0173\n",
      "!!!NEW BEST VAL ACC 0.10416666666666667\n",
      "\n",
      "Current Best Val Acc: 0.1042 Validation Loss: 171.1315, Validation Accuracy: 0.1042\n",
      "Epoch 3/300, Loss: 230.7144\n",
      "!!!NEW BEST VAL ACC 0.14583333333333334\n",
      "\n",
      "Current Best Val Acc: 0.1458 Validation Loss: 170.0349, Validation Accuracy: 0.1458\n",
      "Epoch 4/300, Loss: 190.4150\n",
      "!!!NEW BEST VAL ACC 0.3125\n",
      "\n",
      "Current Best Val Acc: 0.3125 Validation Loss: 147.8883, Validation Accuracy: 0.3125\n",
      "Epoch 5/300, Loss: 143.4712\n",
      "Current Best Val Acc: 0.3125 Validation Loss: 126.2443, Validation Accuracy: 0.2917\n",
      "Epoch 6/300, Loss: 98.9613\n",
      "!!!NEW BEST VAL ACC 0.5416666666666666\n",
      "\n",
      "Current Best Val Acc: 0.5417 Validation Loss: 101.4525, Validation Accuracy: 0.5417\n",
      "Epoch 7/300, Loss: 66.1829\n",
      "!!!NEW BEST VAL ACC 0.6666666666666666\n",
      "\n",
      "Current Best Val Acc: 0.6667 Validation Loss: 79.8632, Validation Accuracy: 0.6667\n",
      "Epoch 8/300, Loss: 41.9512\n",
      "!!!NEW BEST VAL ACC 0.8958333333333334\n",
      "\n",
      "Current Best Val Acc: 0.8958 Validation Loss: 58.9395, Validation Accuracy: 0.8958\n",
      "Epoch 9/300, Loss: 23.9902\n",
      "Current Best Val Acc: 0.8958 Validation Loss: 58.0660, Validation Accuracy: 0.8958\n",
      "Epoch 10/300, Loss: 17.7414\n",
      "Current Best Val Acc: 0.8958 Validation Loss: 62.3472, Validation Accuracy: 0.8750\n",
      "Epoch 11/300, Loss: 12.3642\n",
      "Current Best Val Acc: 0.8958 Validation Loss: 62.4223, Validation Accuracy: 0.8750\n",
      "Epoch 12/300, Loss: 11.9134\n",
      "Current Best Val Acc: 0.8958 Validation Loss: 65.1662, Validation Accuracy: 0.8750\n",
      "Epoch 13/300, Loss: 11.1672\n",
      "!!!NEW BEST VAL ACC 0.9166666666666666\n",
      "\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 63.6224, Validation Accuracy: 0.9167\n",
      "Epoch 14/300, Loss: 10.6999\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 59.5910, Validation Accuracy: 0.9167\n",
      "Epoch 15/300, Loss: 6.9912\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 66.9953, Validation Accuracy: 0.8958\n",
      "Epoch 16/300, Loss: 8.9701\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 65.2950, Validation Accuracy: 0.8958\n",
      "Epoch 17/300, Loss: 8.9536\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 64.9302, Validation Accuracy: 0.8958\n",
      "Epoch 18/300, Loss: 6.2188\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 67.0973, Validation Accuracy: 0.8958\n",
      "Epoch 19/300, Loss: 7.1665\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 66.9556, Validation Accuracy: 0.8958\n",
      "Epoch 20/300, Loss: 5.7624\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 65.3560, Validation Accuracy: 0.8958\n",
      "Epoch 21/300, Loss: 6.5484\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 69.1318, Validation Accuracy: 0.8958\n",
      "Epoch 22/300, Loss: 7.1901\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 69.4594, Validation Accuracy: 0.8958\n",
      "Epoch 23/300, Loss: 6.7468\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 64.4176, Validation Accuracy: 0.8958\n",
      "Epoch 24/300, Loss: 5.7593\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 68.2193, Validation Accuracy: 0.8958\n",
      "Epoch 25/300, Loss: 5.4819\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 65.5727, Validation Accuracy: 0.9167\n",
      "Epoch 26/300, Loss: 5.2601\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 70.3301, Validation Accuracy: 0.8958\n",
      "Epoch 27/300, Loss: 4.9515\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 67.5076, Validation Accuracy: 0.9167\n",
      "Epoch 28/300, Loss: 4.9772\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 70.6514, Validation Accuracy: 0.8958\n",
      "Epoch 29/300, Loss: 5.3378\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 73.3490, Validation Accuracy: 0.8958\n",
      "Epoch 30/300, Loss: 4.7215\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 68.4802, Validation Accuracy: 0.9167\n",
      "Epoch 31/300, Loss: 4.3600\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 69.0092, Validation Accuracy: 0.9167\n",
      "Epoch 32/300, Loss: 5.2288\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 71.5656, Validation Accuracy: 0.9167\n",
      "Epoch 33/300, Loss: 5.3231\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 71.2428, Validation Accuracy: 0.8958\n",
      "Epoch 34/300, Loss: 5.0788\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 73.9544, Validation Accuracy: 0.8958\n",
      "Epoch 35/300, Loss: 5.4008\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 71.8565, Validation Accuracy: 0.8958\n",
      "Epoch 36/300, Loss: 4.9707\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 74.2179, Validation Accuracy: 0.8958\n",
      "Epoch 37/300, Loss: 4.7139\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 73.2402, Validation Accuracy: 0.8958\n",
      "Epoch 38/300, Loss: 4.8055\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 67.5931, Validation Accuracy: 0.9167\n",
      "Epoch 39/300, Loss: 3.9589\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 73.0280, Validation Accuracy: 0.8958\n",
      "Epoch 40/300, Loss: 4.2450\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 76.7499, Validation Accuracy: 0.8958\n",
      "Epoch 41/300, Loss: 4.5002\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 75.4236, Validation Accuracy: 0.8958\n",
      "Epoch 42/300, Loss: 4.5022\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 71.9314, Validation Accuracy: 0.8958\n",
      "Epoch 43/300, Loss: 4.0218\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 71.9171, Validation Accuracy: 0.8958\n",
      "Epoch 44/300, Loss: 3.6635\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 73.7416, Validation Accuracy: 0.8958\n",
      "Epoch 45/300, Loss: 3.5681\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 80.0324, Validation Accuracy: 0.8958\n",
      "Epoch 46/300, Loss: 4.4806\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 76.7377, Validation Accuracy: 0.8958\n",
      "Epoch 47/300, Loss: 3.4369\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 80.1310, Validation Accuracy: 0.8958\n",
      "Epoch 48/300, Loss: 3.5428\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 79.7390, Validation Accuracy: 0.8958\n",
      "Epoch 49/300, Loss: 3.5611\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 76.6902, Validation Accuracy: 0.8958\n",
      "Epoch 50/300, Loss: 2.9380\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 80.0864, Validation Accuracy: 0.8958\n",
      "Epoch 51/300, Loss: 2.7816\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 84.7796, Validation Accuracy: 0.8958\n",
      "Epoch 52/300, Loss: 3.3052\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 81.2403, Validation Accuracy: 0.8958\n",
      "Epoch 53/300, Loss: 3.2453\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 81.3087, Validation Accuracy: 0.8958\n",
      "Epoch 54/300, Loss: 3.0317\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 79.5615, Validation Accuracy: 0.8958\n",
      "Epoch 55/300, Loss: 3.1963\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 80.9902, Validation Accuracy: 0.8958\n",
      "Epoch 56/300, Loss: 2.3664\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 84.5021, Validation Accuracy: 0.8958\n",
      "Epoch 57/300, Loss: 2.8986\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 86.2322, Validation Accuracy: 0.8958\n",
      "Epoch 58/300, Loss: 2.9056\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 82.9438, Validation Accuracy: 0.8958\n",
      "Epoch 59/300, Loss: 2.5714\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 82.6929, Validation Accuracy: 0.8958\n",
      "Epoch 60/300, Loss: 2.4775\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 85.5034, Validation Accuracy: 0.8958\n",
      "Epoch 61/300, Loss: 3.3420\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 81.1701, Validation Accuracy: 0.8958\n",
      "Epoch 62/300, Loss: 2.8510\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 85.2108, Validation Accuracy: 0.8958\n",
      "Epoch 63/300, Loss: 3.6007\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 79.9588, Validation Accuracy: 0.8958\n",
      "Epoch 64/300, Loss: 2.9591\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 81.1734, Validation Accuracy: 0.8958\n",
      "Epoch 65/300, Loss: 2.7275\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 82.0185, Validation Accuracy: 0.8958\n",
      "Epoch 66/300, Loss: 3.2208\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 82.5453, Validation Accuracy: 0.8958\n",
      "Epoch 67/300, Loss: 2.9704\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 80.7938, Validation Accuracy: 0.8958\n",
      "Epoch 68/300, Loss: 2.5328\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 84.2123, Validation Accuracy: 0.8958\n",
      "Epoch 69/300, Loss: 2.7442\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 82.8494, Validation Accuracy: 0.8958\n",
      "Epoch 70/300, Loss: 2.7253\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 84.8748, Validation Accuracy: 0.8958\n",
      "Epoch 71/300, Loss: 2.9127\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 82.1303, Validation Accuracy: 0.8958\n",
      "Epoch 72/300, Loss: 2.3464\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 86.6355, Validation Accuracy: 0.8958\n",
      "Epoch 73/300, Loss: 2.3234\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 86.6795, Validation Accuracy: 0.8958\n",
      "Epoch 74/300, Loss: 2.7891\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 83.7697, Validation Accuracy: 0.8958\n",
      "Epoch 75/300, Loss: 2.5199\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 85.5327, Validation Accuracy: 0.8958\n",
      "Epoch 76/300, Loss: 2.4620\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 86.1472, Validation Accuracy: 0.8958\n",
      "Epoch 77/300, Loss: 2.7964\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 85.9268, Validation Accuracy: 0.8958\n",
      "Epoch 78/300, Loss: 2.3414\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 84.9283, Validation Accuracy: 0.8958\n",
      "Epoch 79/300, Loss: 2.8046\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 84.3261, Validation Accuracy: 0.8958\n",
      "Epoch 80/300, Loss: 2.7625\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 84.1136, Validation Accuracy: 0.8958\n",
      "Epoch 81/300, Loss: 2.4359\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 84.4718, Validation Accuracy: 0.8958\n",
      "Epoch 82/300, Loss: 2.6754\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 85.8781, Validation Accuracy: 0.8958\n",
      "Epoch 83/300, Loss: 2.3055\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 86.7012, Validation Accuracy: 0.8958\n",
      "Epoch 84/300, Loss: 2.7516\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 83.0067, Validation Accuracy: 0.8958\n",
      "Epoch 85/300, Loss: 2.5491\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 85.6229, Validation Accuracy: 0.8958\n",
      "Epoch 86/300, Loss: 2.5848\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 83.3166, Validation Accuracy: 0.8958\n",
      "Epoch 87/300, Loss: 2.5213\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 86.3283, Validation Accuracy: 0.8958\n",
      "Epoch 88/300, Loss: 2.2369\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 89.3180, Validation Accuracy: 0.8958\n",
      "Epoch 89/300, Loss: 2.2768\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 89.6948, Validation Accuracy: 0.8958\n",
      "Epoch 90/300, Loss: 2.3972\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 90.5229, Validation Accuracy: 0.8958\n",
      "Epoch 91/300, Loss: 2.1531\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 89.5061, Validation Accuracy: 0.8958\n",
      "Epoch 92/300, Loss: 1.9342\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 95.4261, Validation Accuracy: 0.8958\n",
      "Epoch 93/300, Loss: 2.7274\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 85.9282, Validation Accuracy: 0.8958\n",
      "Epoch 94/300, Loss: 2.2854\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 89.2795, Validation Accuracy: 0.8958\n",
      "Epoch 95/300, Loss: 2.3682\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 89.2990, Validation Accuracy: 0.8958\n",
      "Epoch 96/300, Loss: 2.4766\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 88.1277, Validation Accuracy: 0.8958\n",
      "Epoch 97/300, Loss: 2.1162\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 92.2283, Validation Accuracy: 0.8958\n",
      "Epoch 98/300, Loss: 2.6987\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 84.6872, Validation Accuracy: 0.8958\n",
      "Epoch 99/300, Loss: 2.2462\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 89.7101, Validation Accuracy: 0.8958\n",
      "Epoch 100/300, Loss: 2.2910\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 88.1718, Validation Accuracy: 0.8958\n",
      "Epoch 101/300, Loss: 2.2277\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 89.8058, Validation Accuracy: 0.8958\n",
      "Epoch 102/300, Loss: 2.1139\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 93.3572, Validation Accuracy: 0.8958\n",
      "Epoch 103/300, Loss: 2.6367\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 87.0701, Validation Accuracy: 0.8958\n",
      "Epoch 104/300, Loss: 2.4026\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 90.7372, Validation Accuracy: 0.8958\n",
      "Epoch 105/300, Loss: 2.5047\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 94.9395, Validation Accuracy: 0.8958\n",
      "Epoch 106/300, Loss: 2.1751\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 89.7049, Validation Accuracy: 0.8958\n",
      "Epoch 107/300, Loss: 2.5722\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 96.6212, Validation Accuracy: 0.8958\n",
      "Epoch 108/300, Loss: 2.1944\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 89.6029, Validation Accuracy: 0.8958\n",
      "Epoch 109/300, Loss: 2.2053\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 90.1995, Validation Accuracy: 0.8958\n",
      "Epoch 110/300, Loss: 2.5185\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 90.1562, Validation Accuracy: 0.8958\n",
      "Epoch 111/300, Loss: 2.2852\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 90.6207, Validation Accuracy: 0.8958\n",
      "Epoch 112/300, Loss: 2.2454\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 89.7256, Validation Accuracy: 0.8958\n",
      "Epoch 113/300, Loss: 2.3651\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 87.2580, Validation Accuracy: 0.8958\n",
      "Epoch 114/300, Loss: 2.1541\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 87.0006, Validation Accuracy: 0.8958\n",
      "Epoch 115/300, Loss: 2.6041\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 83.5231, Validation Accuracy: 0.8958\n",
      "Epoch 116/300, Loss: 2.1375\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 88.3351, Validation Accuracy: 0.8958\n",
      "Epoch 117/300, Loss: 2.1656\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 89.4153, Validation Accuracy: 0.8958\n",
      "Epoch 118/300, Loss: 2.2474\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 91.6990, Validation Accuracy: 0.8958\n",
      "Epoch 119/300, Loss: 2.1147\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 91.2714, Validation Accuracy: 0.8958\n",
      "Epoch 120/300, Loss: 2.0547\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 94.0767, Validation Accuracy: 0.8958\n",
      "Epoch 121/300, Loss: 2.1071\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 93.2260, Validation Accuracy: 0.8958\n",
      "Epoch 122/300, Loss: 2.1414\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 93.3073, Validation Accuracy: 0.8958\n",
      "Epoch 123/300, Loss: 2.1038\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 96.2288, Validation Accuracy: 0.8958\n",
      "Epoch 124/300, Loss: 2.0766\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 97.2507, Validation Accuracy: 0.8958\n",
      "Epoch 125/300, Loss: 2.2391\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 99.3471, Validation Accuracy: 0.8958\n",
      "Epoch 126/300, Loss: 3.8899\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 81.6280, Validation Accuracy: 0.8958\n",
      "Epoch 127/300, Loss: 3.3024\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 77.0638, Validation Accuracy: 0.8958\n",
      "Epoch 128/300, Loss: 2.4206\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 83.4516, Validation Accuracy: 0.8958\n",
      "Epoch 129/300, Loss: 2.3649\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 86.3040, Validation Accuracy: 0.8958\n",
      "Epoch 130/300, Loss: 2.4506\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 85.0451, Validation Accuracy: 0.8958\n",
      "Epoch 131/300, Loss: 2.1957\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 88.0345, Validation Accuracy: 0.8958\n",
      "Epoch 132/300, Loss: 2.3776\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 88.0114, Validation Accuracy: 0.8958\n",
      "Epoch 133/300, Loss: 2.1736\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 90.1461, Validation Accuracy: 0.8958\n",
      "Epoch 134/300, Loss: 2.2760\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 86.7760, Validation Accuracy: 0.8958\n",
      "Epoch 135/300, Loss: 2.5582\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 80.8232, Validation Accuracy: 0.8958\n",
      "Epoch 136/300, Loss: 2.0700\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 86.8919, Validation Accuracy: 0.8958\n",
      "Epoch 137/300, Loss: 2.1745\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 88.3747, Validation Accuracy: 0.8958\n",
      "Epoch 138/300, Loss: 2.0671\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 90.0232, Validation Accuracy: 0.8958\n",
      "Epoch 139/300, Loss: 2.0953\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 90.5210, Validation Accuracy: 0.8958\n",
      "Epoch 140/300, Loss: 1.9936\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 93.7877, Validation Accuracy: 0.8958\n",
      "Epoch 141/300, Loss: 2.0841\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 93.9864, Validation Accuracy: 0.8958\n",
      "Epoch 142/300, Loss: 2.1428\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 91.6798, Validation Accuracy: 0.8958\n",
      "Epoch 143/300, Loss: 2.1383\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 92.0874, Validation Accuracy: 0.8958\n",
      "Epoch 144/300, Loss: 2.1755\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 93.0752, Validation Accuracy: 0.8958\n",
      "Epoch 145/300, Loss: 2.0611\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 93.3550, Validation Accuracy: 0.8958\n",
      "Epoch 146/300, Loss: 2.0563\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 92.7868, Validation Accuracy: 0.8958\n",
      "Epoch 147/300, Loss: 2.1661\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 97.8263, Validation Accuracy: 0.8958\n",
      "Epoch 148/300, Loss: 3.3322\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 81.8833, Validation Accuracy: 0.8958\n",
      "Epoch 149/300, Loss: 2.3135\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 81.7153, Validation Accuracy: 0.8958\n",
      "Epoch 150/300, Loss: 2.0051\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 86.4284, Validation Accuracy: 0.8958\n",
      "Epoch 151/300, Loss: 2.2145\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 87.3651, Validation Accuracy: 0.8958\n",
      "Epoch 152/300, Loss: 2.1214\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 86.4335, Validation Accuracy: 0.8958\n",
      "Epoch 153/300, Loss: 2.0620\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 90.8078, Validation Accuracy: 0.8958\n",
      "Epoch 154/300, Loss: 2.0154\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 90.4953, Validation Accuracy: 0.8958\n",
      "Epoch 155/300, Loss: 2.1556\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 89.5679, Validation Accuracy: 0.8958\n",
      "Epoch 156/300, Loss: 1.9880\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 91.8245, Validation Accuracy: 0.8958\n",
      "Epoch 157/300, Loss: 1.9492\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 94.0926, Validation Accuracy: 0.8958\n",
      "Epoch 158/300, Loss: 2.0976\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 92.6521, Validation Accuracy: 0.8958\n",
      "Epoch 159/300, Loss: 2.0619\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 92.6969, Validation Accuracy: 0.8958\n",
      "Epoch 160/300, Loss: 2.0670\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 93.3111, Validation Accuracy: 0.8958\n",
      "Epoch 161/300, Loss: 2.1154\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 98.5890, Validation Accuracy: 0.8958\n",
      "Epoch 162/300, Loss: 2.0735\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 93.8420, Validation Accuracy: 0.8958\n",
      "Epoch 163/300, Loss: 2.0059\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 94.4618, Validation Accuracy: 0.8958\n",
      "Epoch 164/300, Loss: 2.0255\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 96.3874, Validation Accuracy: 0.8958\n",
      "Epoch 165/300, Loss: 2.0220\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 94.3912, Validation Accuracy: 0.8958\n",
      "Epoch 166/300, Loss: 2.0049\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 97.1880, Validation Accuracy: 0.8958\n",
      "Epoch 167/300, Loss: 2.0299\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 98.7728, Validation Accuracy: 0.8958\n",
      "Epoch 168/300, Loss: 2.0577\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 95.9735, Validation Accuracy: 0.8958\n",
      "Epoch 169/300, Loss: 1.9839\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 97.6950, Validation Accuracy: 0.8958\n",
      "Epoch 170/300, Loss: 2.0517\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 98.5507, Validation Accuracy: 0.8958\n",
      "Epoch 171/300, Loss: 2.0623\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 99.3313, Validation Accuracy: 0.8958\n",
      "Epoch 172/300, Loss: 2.0247\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 99.7260, Validation Accuracy: 0.8958\n",
      "Epoch 173/300, Loss: 2.0563\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 99.1102, Validation Accuracy: 0.8958\n",
      "Epoch 174/300, Loss: 2.0322\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 101.0417, Validation Accuracy: 0.8958\n",
      "Epoch 175/300, Loss: 2.0660\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 99.1235, Validation Accuracy: 0.8958\n",
      "Epoch 176/300, Loss: 2.0315\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 99.3197, Validation Accuracy: 0.8958\n",
      "Epoch 177/300, Loss: 1.9521\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 102.0063, Validation Accuracy: 0.8958\n",
      "Epoch 178/300, Loss: 2.0558\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 100.4919, Validation Accuracy: 0.8958\n",
      "Epoch 179/300, Loss: 1.9586\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 99.8485, Validation Accuracy: 0.8958\n",
      "Epoch 180/300, Loss: 2.0205\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 99.7779, Validation Accuracy: 0.8958\n",
      "Epoch 181/300, Loss: 1.9682\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 101.7735, Validation Accuracy: 0.8958\n",
      "Epoch 182/300, Loss: 2.0186\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 100.3099, Validation Accuracy: 0.8958\n",
      "Epoch 183/300, Loss: 2.0165\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 99.7328, Validation Accuracy: 0.8958\n",
      "Epoch 184/300, Loss: 1.9497\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 102.0062, Validation Accuracy: 0.8958\n",
      "Epoch 185/300, Loss: 2.0181\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 101.7068, Validation Accuracy: 0.8958\n",
      "Epoch 186/300, Loss: 2.0084\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 101.6159, Validation Accuracy: 0.8958\n",
      "Epoch 187/300, Loss: 1.9950\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 101.9376, Validation Accuracy: 0.8958\n",
      "Epoch 188/300, Loss: 1.9858\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 101.0610, Validation Accuracy: 0.8958\n",
      "Epoch 189/300, Loss: 1.9778\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 102.1026, Validation Accuracy: 0.8958\n",
      "Epoch 190/300, Loss: 2.0009\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 103.2044, Validation Accuracy: 0.8958\n",
      "Epoch 191/300, Loss: 1.9827\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 103.6207, Validation Accuracy: 0.8958\n",
      "Epoch 192/300, Loss: 2.0174\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 102.4496, Validation Accuracy: 0.8958\n",
      "Epoch 193/300, Loss: 2.0561\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 103.0418, Validation Accuracy: 0.8958\n",
      "Epoch 194/300, Loss: 2.0384\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 103.1977, Validation Accuracy: 0.8958\n",
      "Epoch 195/300, Loss: 1.9837\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 103.5403, Validation Accuracy: 0.8958\n",
      "Epoch 196/300, Loss: 2.0318\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 103.1541, Validation Accuracy: 0.8958\n",
      "Epoch 197/300, Loss: 1.9949\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 103.1588, Validation Accuracy: 0.8958\n",
      "Epoch 198/300, Loss: 2.0015\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 104.8174, Validation Accuracy: 0.8958\n",
      "Epoch 199/300, Loss: 1.9930\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 103.7453, Validation Accuracy: 0.8958\n",
      "Epoch 200/300, Loss: 2.0152\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 104.4771, Validation Accuracy: 0.8958\n",
      "Epoch 201/300, Loss: 1.9940\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 105.5216, Validation Accuracy: 0.8958\n",
      "Epoch 202/300, Loss: 1.9515\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 105.6891, Validation Accuracy: 0.8958\n",
      "Epoch 203/300, Loss: 1.9388\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 106.2916, Validation Accuracy: 0.8958\n",
      "Epoch 204/300, Loss: 2.0119\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 105.1264, Validation Accuracy: 0.8958\n",
      "Epoch 205/300, Loss: 1.9551\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 106.5428, Validation Accuracy: 0.8958\n",
      "Epoch 206/300, Loss: 1.9846\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 105.9883, Validation Accuracy: 0.8958\n",
      "Epoch 207/300, Loss: 2.0224\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 107.7773, Validation Accuracy: 0.8958\n",
      "Epoch 208/300, Loss: 1.9946\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 108.3308, Validation Accuracy: 0.8958\n",
      "Epoch 209/300, Loss: 1.9579\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 105.5974, Validation Accuracy: 0.8958\n",
      "Epoch 210/300, Loss: 1.9433\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 105.0818, Validation Accuracy: 0.8958\n",
      "Epoch 211/300, Loss: 1.9362\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 107.1514, Validation Accuracy: 0.8958\n",
      "Epoch 212/300, Loss: 1.9844\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 106.9517, Validation Accuracy: 0.8958\n",
      "Epoch 213/300, Loss: 1.9626\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 106.8752, Validation Accuracy: 0.8958\n",
      "Epoch 214/300, Loss: 1.9818\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 107.0310, Validation Accuracy: 0.8958\n",
      "Epoch 215/300, Loss: 1.9997\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 109.0706, Validation Accuracy: 0.8958\n",
      "Epoch 216/300, Loss: 2.0024\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 108.9076, Validation Accuracy: 0.8958\n",
      "Epoch 217/300, Loss: 1.9443\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 107.7622, Validation Accuracy: 0.8958\n",
      "Epoch 218/300, Loss: 1.9908\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 107.4046, Validation Accuracy: 0.8958\n",
      "Epoch 219/300, Loss: 1.9704\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 107.1688, Validation Accuracy: 0.8958\n",
      "Epoch 220/300, Loss: 1.9942\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 108.6952, Validation Accuracy: 0.8958\n",
      "Epoch 221/300, Loss: 1.9299\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 109.7429, Validation Accuracy: 0.8958\n",
      "Epoch 222/300, Loss: 2.0255\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 107.1423, Validation Accuracy: 0.8958\n",
      "Epoch 223/300, Loss: 1.9862\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 106.6829, Validation Accuracy: 0.8958\n",
      "Epoch 224/300, Loss: 2.0107\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 104.1117, Validation Accuracy: 0.8958\n",
      "Epoch 225/300, Loss: 2.0269\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 103.1384, Validation Accuracy: 0.8958\n",
      "Epoch 226/300, Loss: 2.0242\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 104.9630, Validation Accuracy: 0.8958\n",
      "Epoch 227/300, Loss: 1.9349\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 109.0485, Validation Accuracy: 0.8958\n",
      "Epoch 228/300, Loss: 2.0023\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 106.4214, Validation Accuracy: 0.8958\n",
      "Epoch 229/300, Loss: 1.9956\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 109.6698, Validation Accuracy: 0.8958\n",
      "Epoch 230/300, Loss: 1.9923\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 105.8829, Validation Accuracy: 0.8958\n",
      "Epoch 231/300, Loss: 1.9351\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 106.3016, Validation Accuracy: 0.8958\n",
      "Epoch 232/300, Loss: 1.9523\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 106.2404, Validation Accuracy: 0.8958\n",
      "Epoch 233/300, Loss: 1.9902\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 106.3801, Validation Accuracy: 0.8958\n",
      "Epoch 234/300, Loss: 1.9652\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 106.6726, Validation Accuracy: 0.8958\n",
      "Epoch 235/300, Loss: 1.9582\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 106.9106, Validation Accuracy: 0.8958\n",
      "Epoch 236/300, Loss: 1.9484\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 107.7773, Validation Accuracy: 0.8958\n",
      "Epoch 237/300, Loss: 1.9773\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 107.7640, Validation Accuracy: 0.8958\n",
      "Epoch 238/300, Loss: 1.9643\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 107.8576, Validation Accuracy: 0.8958\n",
      "Epoch 239/300, Loss: 1.9850\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 107.4341, Validation Accuracy: 0.8958\n",
      "Epoch 240/300, Loss: 1.9595\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 107.1543, Validation Accuracy: 0.8958\n",
      "Epoch 241/300, Loss: 1.9437\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 107.6876, Validation Accuracy: 0.8958\n",
      "Epoch 242/300, Loss: 1.9480\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 107.7889, Validation Accuracy: 0.8958\n",
      "Epoch 243/300, Loss: 1.9752\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 109.3939, Validation Accuracy: 0.8958\n",
      "Epoch 244/300, Loss: 2.0053\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 107.7168, Validation Accuracy: 0.8958\n",
      "Epoch 245/300, Loss: 1.9438\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 107.8702, Validation Accuracy: 0.8958\n",
      "Epoch 246/300, Loss: 1.9652\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 108.8742, Validation Accuracy: 0.8958\n",
      "Epoch 247/300, Loss: 1.9638\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 109.4644, Validation Accuracy: 0.8958\n",
      "Epoch 248/300, Loss: 1.9456\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 109.0632, Validation Accuracy: 0.8958\n",
      "Epoch 249/300, Loss: 1.9568\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 109.3666, Validation Accuracy: 0.8958\n",
      "Epoch 250/300, Loss: 1.9508\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 109.4784, Validation Accuracy: 0.8958\n",
      "Epoch 251/300, Loss: 1.9356\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 109.9694, Validation Accuracy: 0.8958\n",
      "Epoch 252/300, Loss: 1.9545\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 110.0115, Validation Accuracy: 0.8958\n",
      "Epoch 253/300, Loss: 1.9570\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 109.9494, Validation Accuracy: 0.8958\n",
      "Epoch 254/300, Loss: 1.9383\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 109.9804, Validation Accuracy: 0.8958\n",
      "Epoch 255/300, Loss: 1.9439\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 110.9307, Validation Accuracy: 0.8958\n",
      "Epoch 256/300, Loss: 1.9404\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 111.1245, Validation Accuracy: 0.8958\n",
      "Epoch 257/300, Loss: 1.9521\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 112.2563, Validation Accuracy: 0.8958\n",
      "Epoch 258/300, Loss: 1.9427\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 111.5209, Validation Accuracy: 0.8958\n",
      "Epoch 259/300, Loss: 1.9454\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 110.6114, Validation Accuracy: 0.8958\n",
      "Epoch 260/300, Loss: 1.9450\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 110.9680, Validation Accuracy: 0.8958\n",
      "Epoch 261/300, Loss: 1.9713\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 110.5000, Validation Accuracy: 0.8958\n",
      "Epoch 262/300, Loss: 1.9462\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 111.3853, Validation Accuracy: 0.8958\n",
      "Epoch 263/300, Loss: 1.9358\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 111.1434, Validation Accuracy: 0.8958\n",
      "Epoch 264/300, Loss: 1.9307\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 111.6072, Validation Accuracy: 0.8958\n",
      "Epoch 265/300, Loss: 1.9369\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 111.5556, Validation Accuracy: 0.8958\n",
      "Epoch 266/300, Loss: 1.9535\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 112.0242, Validation Accuracy: 0.8958\n",
      "Epoch 267/300, Loss: 1.9337\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 112.1425, Validation Accuracy: 0.8958\n",
      "Epoch 268/300, Loss: 1.9248\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 111.9651, Validation Accuracy: 0.8958\n",
      "Epoch 269/300, Loss: 1.9511\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 112.6921, Validation Accuracy: 0.8958\n",
      "Epoch 270/300, Loss: 1.9412\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 112.0480, Validation Accuracy: 0.8958\n",
      "Epoch 271/300, Loss: 1.9352\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 112.0219, Validation Accuracy: 0.8958\n",
      "Epoch 272/300, Loss: 1.9268\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 112.4315, Validation Accuracy: 0.8958\n",
      "Epoch 273/300, Loss: 1.9437\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 112.4797, Validation Accuracy: 0.8958\n",
      "Epoch 274/300, Loss: 1.9273\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 112.6631, Validation Accuracy: 0.8958\n",
      "Epoch 275/300, Loss: 1.9397\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 111.9977, Validation Accuracy: 0.8958\n",
      "Epoch 276/300, Loss: 1.9455\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 113.5455, Validation Accuracy: 0.8958\n",
      "Epoch 277/300, Loss: 1.9300\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 113.8921, Validation Accuracy: 0.8958\n",
      "Epoch 278/300, Loss: 1.9209\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 112.9227, Validation Accuracy: 0.8958\n",
      "Epoch 279/300, Loss: 1.9324\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 112.7786, Validation Accuracy: 0.8958\n",
      "Epoch 280/300, Loss: 1.9322\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 113.0436, Validation Accuracy: 0.8958\n",
      "Epoch 281/300, Loss: 1.9257\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 113.0477, Validation Accuracy: 0.8958\n",
      "Epoch 282/300, Loss: 1.9268\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 113.4734, Validation Accuracy: 0.8958\n",
      "Epoch 283/300, Loss: 1.9221\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 113.6457, Validation Accuracy: 0.8958\n",
      "Epoch 284/300, Loss: 1.9183\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 113.7066, Validation Accuracy: 0.8958\n",
      "Epoch 285/300, Loss: 1.9260\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 114.2651, Validation Accuracy: 0.8958\n",
      "Epoch 286/300, Loss: 1.9168\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 113.8378, Validation Accuracy: 0.8958\n",
      "Epoch 287/300, Loss: 1.9249\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 114.0282, Validation Accuracy: 0.8958\n",
      "Epoch 288/300, Loss: 1.9192\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 114.1398, Validation Accuracy: 0.8958\n",
      "Epoch 289/300, Loss: 1.9151\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 114.1641, Validation Accuracy: 0.8958\n",
      "Epoch 290/300, Loss: 1.9186\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 114.3364, Validation Accuracy: 0.8958\n",
      "Epoch 291/300, Loss: 1.9134\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 114.3964, Validation Accuracy: 0.8958\n",
      "Epoch 292/300, Loss: 1.9165\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 114.4700, Validation Accuracy: 0.8958\n",
      "Epoch 293/300, Loss: 1.9156\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 114.7463, Validation Accuracy: 0.8958\n",
      "Epoch 294/300, Loss: 1.9137\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 114.7756, Validation Accuracy: 0.8958\n",
      "Epoch 295/300, Loss: 1.9138\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 114.8109, Validation Accuracy: 0.8958\n",
      "Epoch 296/300, Loss: 1.9125\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 114.8960, Validation Accuracy: 0.8958\n",
      "Epoch 297/300, Loss: 1.9137\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 114.8793, Validation Accuracy: 0.8958\n",
      "Epoch 298/300, Loss: 1.9113\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 114.9369, Validation Accuracy: 0.8958\n",
      "Epoch 299/300, Loss: 1.9128\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 114.9853, Validation Accuracy: 0.8958\n",
      "Epoch 300/300, Loss: 1.9129\n",
      "Current Best Val Acc: 0.9167 Validation Loss: 114.9708, Validation Accuracy: 0.8958\n",
      "Test Accuracy: 0.9167\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "best_model = train_model(model, train_loader, validation_loader, criterion, optimizer, num_epochs=300)\n",
    "\n",
    "# Evaluate\n",
    "evaluate_model(best_model, validation_loader)\n",
    "\n",
    "# Save the model\n",
    "best_model.eval()\n",
    "torch.save(best_model.state_dict(), 'imda_technical_test_pytorch_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c88af1de-a452-47e6-a54b-ab9a00ca64bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'InferredCharacters': '20BHQ'} {'InferredCharacters': 'YMB1Q'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\TorchInferenceEngine.py:44: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch_model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD//gA+Q1JFQVRPUjogZ2QtanBlZyB2MS4wICh1c2luZyBJSkcgSlBFRyB2NjIpLCBkZWZhdWx0IHF1YWxpdHkK/9sAQwAIBgYHBgUIBwcHCQkICgwUDQwLCwwZEhMPFB0aHx4dGhwcICQuJyAiLCMcHCg3KSwwMTQ0NB8nOT04MjwuMzQy/9sAQwEJCQkMCwwYDQ0YMiEcITIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIy/8AAEQgAHgA8AwEiAAIRAQMRAf/EAB8AAAEFAQEBAQEBAAAAAAAAAAABAgMEBQYHCAkKC//EALUQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+v/EAB8BAAMBAQEBAQEBAQEAAAAAAAABAgMEBQYHCAkKC//EALURAAIBAgQEAwQHBQQEAAECdwABAgMRBAUhMQYSQVEHYXETIjKBCBRCkaGxwQkjM1LwFWJy0QoWJDThJfEXGBkaJicoKSo1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoKDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uLj5OXm5+jp6vLz9PX29/j5+v/aAAwDAQACEQMRAD8A9xma8hQN50By6r/qT3YD+971G9zNFcNFLd2seEVgXjIzkkf3/b9ap+KZtVg0Y/2NZrcX8s0UcXmyBIoiXH7yQ5yUHcKCx4AHcce/jaXwxr+uQeJbiO8GmWEdy15p8BVQruqrC8ZY7JSxyuWIKsCdoBoA7Sa8B8tGureVSwc+UFH3WB6l8DP+NSLqpaDzVW1J2F/LFx82AM4xt61xV3471/w/bXkPibTLO01G5sLq+0kW0jTxkxRl2gmxg+YgwSy4RgTggjmhovj6+1y98PQPdabrA1CEy3tnpVvKk2n5jGWcmR1KKW2tna2SNoY5WgD0q2tLaWN3kt4nYyyZZkBJ+c0k8VraTW0ojhhHmkFwoXjY3evJF+MbxfC1dbjvdEPiEuxbTjuyMzkfd8zd9z5uv6Vu3XjPXbqz8Q63p0em/wBm+HLx4HguYpFnuniH7/DB8RDa2E4ckjkL0oA7mO5idWZ9TCHe4Cho8ABiB1Hpin292Gh+Z5JCGYb1hZgwDEA5UY6Y6VS0vUl1Tw3pd5FbzJDcxW0yGTbnDbGGcHrg+ldBQByuu2utXGj3C+GLbSrfUGdo4rm7YhYcEguAqHLDHAPGTk5xg8zp3gmWXQrrwrqmkadHYzxOJ7m31GWS4nm3Rv5rs0I3Puw2TkcY27eK9Hs/9S3/AF1k/wDQ2rNlvIrTUZJGVyCWHygZ+7F/hQBwl74N8Sa9bT3PiPULK8vLeyu9P0xrWJ40BliaJp5gFJ3t8oIHyqAcAk8WNP8ADmr3S+EbfUVtLODw4qbbqxaaW4uHjjEflgtEgjicAlx824BRx1r0HT5BJab1BAaRzz15c1Vit1ulM3l2vzyOo32+45DEZJ3c9KAOCj+Hury/An/hCxNaLqfI8x2cRf8AHz5vXbu+7/s9fzqjrHgHXZ/7YstMvfs+m6tqcty9yblkaIzt5U6PCAUnQqFKZ2Mrd+59OitYvtMSSQWrKyM/ywBSCCvufWrnkw+X5HlJ5f8Ac2jb69KAM3TtP/sjwzpWm4x9khtrfHmeZjZsX721d3TrtXPoOlbVZl9Da2lv5628amN0OUQA/eHSo/8AhILT/nnP+Q/xoA//2Q==",
      "image/png": "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",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=60x30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD//gA+Q1JFQVRPUjogZ2QtanBlZyB2MS4wICh1c2luZyBJSkcgSlBFRyB2NjIpLCBkZWZhdWx0IHF1YWxpdHkK/9sAQwAIBgYHBgUIBwcHCQkICgwUDQwLCwwZEhMPFB0aHx4dGhwcICQuJyAiLCMcHCg3KSwwMTQ0NB8nOT04MjwuMzQy/9sAQwEJCQkMCwwYDQ0YMiEcITIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIy/8AAEQgAHgA8AwEiAAIRAQMRAf/EAB8AAAEFAQEBAQEBAAAAAAAAAAABAgMEBQYHCAkKC//EALUQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+v/EAB8BAAMBAQEBAQEBAQEAAAAAAAABAgMEBQYHCAkKC//EALURAAIBAgQEAwQHBQQEAAECdwABAgMRBAUhMQYSQVEHYXETIjKBCBRCkaGxwQkjM1LwFWJy0QoWJDThJfEXGBkaJicoKSo1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoKDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uLj5OXm5+jp6vLz9PX29/j5+v/aAAwDAQACEQMRAD8A9xma8hQN50By6r/qT3YD+971G9zNFcNFLd2seEVgXjIzkkf3/b9azPGN7q2n6PFeaTaC78m7ha7gVS0z24YbxCAQDJ0wCcHkcnArg9a+IepQ6dq3izw9FDd6Ha2Mcdtd30Dobmc3EavsUFSY1VyMkL84OMgGgD0ea8B8tGureVSwc+UFH3WB6l8DP+NSLqpaDzVW1J2F/LFx82AM4xt615fqHxi1YagsNpoK2ixQahHdm8cSkXlrAZGjTy25RW2Zc/eDHAXBNXNF8fX2uXvh6B7rTdYGoQmW9s9Kt5Um0/MYyzkyOpRS21s7WyRtDHK0AelW1pbSxu8lvE7GWTLMgJPzmknitbSa2lEcMI80guFC8bG71xOn+MtYl+Jl34YfTFtdOjs5LuGd4mkml/e7S+FcgIWLAAjPAJxnaK914z126s/EOt6dHpv9m+HLx4HguYpFnuniH7/DB8RDa2E4ckjkL0oA7mO5idWZ9TCHe4Cho8ABiB1Hpin292Gh+Z5JCGYb1hZgwDEA5UY6Y6VS0vUl1Tw3pd5FbzJDcxW0yGTbnDbGGcHrg+ldBQBlwwhiZIrG0AV2CsTg5ViM8Lx0rzJfh3rDfCZvBQm0wakAyGcM4jIFwk3Lbck4OPu+tesWf+pb/rrJ/wChtWbLeRWmoySMrkEsPlAz92L/AAoA4rxl4HuNdvbO60q20+yjSLVI7gIrAyz3MBiEhCR8/MBuY849adp/hzV7pfCNvqK2lnB4cVNt1YtNLcXDxxiPywWiQRxOAS4+bcAo4616Dp8gktN6ggNI5568uaqxW63Smby7X55HUb7fcchiMk7uelAHK2eg+Iv+FlHxOLbTvsJs307y3vJVm8s3Jl83aYcbscbM4/2q57WPAOuz/wBsWWmXv2fTdW1OW5e5NyyNEZ28qdHhAKToVClM7GVu/c+nRWsX2mJJILVlZGf5YApBBX3PrVzyYfL8jyk8v+5tG316UAZunaf/AGR4Z0rTcY+yQ21vjzPMxs2L97au7p12rn0HStqsy+htbS389beNTG6HKIAfvDpUf/CQWn/POf8AIf40Af/Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADwAAAAeCAIAAAD/+uoYAAAJSUlEQVR4AXXYWW/OWxQG8LZetHpMNccQLsyh5oY0BBEX4s6H8V3cuzCERCLmoNQQU1BSMQ9V80yp4fzePj379JywL7a1117rWc9ae+3d/6v2169fvb29lUrl+/fv5tra2p8/f5qNmr5hd/Dgwd++fRsyZEi2Xrx4MX78+Gjevn17/fr1ZcuW2eI+aNAg9kOHDuX+5cuX+vp6wr59+yZNmvTp0ydbNGZBY9zT08Nx5MiRMDdt2iTgu3fvLBPUkoHouP348WPYsGEfPnxoaGio2BAJtL0+kjVk4+vXr2JzDo+6ujoyA2YYc7ZrOWrUqOAyiztHljKEHk1TU9O8efOwxC+k6fEGRROby5cvE0BhDCGlBAI2wy7eNGyqBTYgssOMxfv373kGy5IyVTSTX79+jQTGZI6JxIy7EVqUeMuczefPn5lJwDKYpTqWHM0cUWHGXqXPnTunLs4QK0TZQHOwjY2Nra2tlJWzZ8+GdJxpHj9+PGXKFMEwkzTnv/qG6orHmH748OHPnz8fMWKEMGS+ORy7bC31BqJ2GcNEKwY0EgtvPHBiYCbbYqmW5oULFwahOEK+ePEi5Goyq1atsuYAVEIcJDR37txSj2vXri1YsIA1aBAM3rx5M3r0aMbpWkq7hw8fVhKEuCubXSm9evVKp0YPX5QCy4Vs2IVpi4sEsFcdSzhsMtJpbgUO9FVrPhCNsP/48SOZM04sVDSNAR1EqKOlO0+ePOkc5eBYdJTyJBL0lFkmqDCGhhBYCKIQoMmWTIAZjV2VLs0Jp+zSi2hpVC+ikVMgcBZDJvaUwdJMgwRmONHr6T6nGjw8C7Nnz4Z4/PhxDIIzEC044sGMl90INIaKWEYQiL0Gk6RS5txibKY5f/68pq+SHhgDy9RVhdBVA/dShyD98OFDdF1EFB29AIxv377NXj5AOjo6nFIeJo0+f/58ScJhYKAlq3QCZmjBB4WAKDr15s2bTnXs2LF37951yLacoQTIDDjSOEz5V8T2T2YB8HAL2YkBDrotnFpaWmbNmsUySaKIH+rgUFFytMh4MDBOnz4tT0pbejRlA4UETL4YiKUiQFx3MkJmtdy8eTPM3G8umnDDhg28gmyuCw/Q/NORFy5cwD7Buru7Z86cKUaykgwz0AwEc1Kwkp4tjNUG6P3799krnpkvF0qlFYuLTFBHGrhjsSU9ZwiWBrIlxurCBT6vgYyrpEH45+XLl0gIILC/F4Q9e/bcuXPHeT169EiM5AYXInvQXECnum5MEk6lp0+frrTpEI4rV65kRqB0yST55MkTIGPGjKFJFShRnDhx4tOnTyVmVyyJASTYoimj/5mzzvl6yzDACZz2lSJoW0YYp5bKgIQtNmTQDhQIwZJ89OjR1atXA/HqXb16Fc6aNWsY0GOgcZGTJ0zNIGIIoSsH/alh5On0lFJ7rF+/Pgb9c2IoLVqMJGdDVNC2jNhpa0LqHcvodVG20NK77AsD8rNnzyAHxHFJSa9bwjcbNHAiM9At27ZtExoIJd7mvJuxyVythH6QtDVOUhRehQjqLQdYu3fv1hVsYDlHQyQBQpSNTsA4DBLPlirClBLBFva8YGaWOUcgKGp98/bt27ds2bJ169ZFixbR8JKbqrPkMnBUHLF1/nTzdNzt7e3r1q3DVQDdIqv9+/ezSQlljzQ2zlFuDI4dO4YxA2+W18rRT548WSRF9X3nHu/YsWPChAlr167FUnexZ0yGk1OCI6sVK1YgIFxzc7OSIeDk4TiutCuv/mGtk5AgMCUcOnRIirZVFzO43hNbuenZEpKgnMy4mFNmNmmhQAkJ3BccNsWYbMSLcU5Gaffu3avZAugBYGBIsq2tDU6WmSunTp1ip34cnAgIKRJkL1F3SFT9gwQzQzxzqCPK0aCRM0To6scdWrbcpLwP6X42hT0vXOUpEKXzKVF42YWmJxUIuJmmfyQSa55kbHRIeDhTS0/bwYMH+XNQGDYZ4tFoD9/vMjTovc2pnK3cE8pdu3YBz02wlEMQGDATImeoopbpPQZazhbhyJEjsS9z9ZdCbj0SRUvgj2LcnG80lPJJk+GhogqAJca24p7kUxjHortc/+JOEI5NcmYWL7xLLWnSPwTgPq/LMsZ1OQghoWggM0SRPAjkAwcOXLp0SWKdnZ1sEsOXHZYYswEnnty0ijlNYoseOUouiufp4KIH2JiVQ7e4PEgwNiu/cuhMskA4mDHOIYC1LKOCn3MZN26cGG6eGOKxtgRBmDNnjjfB8+KdcbXdAVteIhmKhEo6B25+hqGFU6JS4p0/DQSWZl137949mfAVC2kJIIe0+2epWCml/tFvGIb6v6StxcAMCmc+BNtiY+zvLQPzxo0bb926lY9SnxaUfhmoil+1jBVSAH/wp06dKqRkKJFwRMDZ+OIDiCU9EqiTu7q6Tpw44dvQ9yM9JQIwOVoaLL0BfeJ/popigFNUanm7kQih7hBB+ILxcUe2izE4Bg8ePFi+fDlZ5fDbuXOnXzpczpw5s2TJEiAi+VjzYGPsHgtBTsJw4ItozJgxw+8mpfGzl82NGzdgIi1cjkgayoHb/4pdfdVZwGJNzm0ApHIIiWorT4T2YKNCbOgdCCwfQwIjqmd8RTD2s0AyeoC9DGWewGzo0RIljZGihoDZSfqzQpkuYgkNY+7yJJdRfadSZqnzNENkJJ5Gd3NBeNSWLl2a7HkKDxFp1eVulgaKHhknLluloocACmb6gV54xioiMVfCPWYTQmymTZvmdYMPjWMyVJ2wL4wJ1Sb77RCMXj6EZIUH/4y4QEcdui03T0MrFU1uIeoMWJZsUxFngi4vjF19AhvU/QjIpQpdmAYXJyBoImau3rnfDoGDa1Zazm6YMEolDcx4ZU4MiaklDYo0eYjYiyc2pTkXNKVlqZyUbAyCJSX8ZCsBZTZDc0S2yvhjpTFAK7XkCVF5IFKm0cMmgaXh7+iVK1dseaR4uXby1FdkgxkQLdHa2koAoihIAJSepYEcJVgGAC0hWJJL6Fj+kXS2OagBWa4Ey1QdFqWSmKGL7WV1XxcvXkzDkjK7lhkI+d8WSlsMwpWQQhCSTNFIibGlUxI9LRqoP5J2XbihSHCs3mZ3RTxJa8pwCq2UXKX9AdKXUXJBQif4e+EnlkpLWOXsgkUFAgFmAXG2UdrVMJKBQAPZRy/ff9Kv+RsbBSrKqzCw1QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=60x30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample Inference of torch trained torch model\n",
    "from TorchInferenceEngine import load_torch_ai_model\n",
    "from PIL import Image\n",
    "\n",
    "torch_ai_model = load_torch_ai_model(model_path = 'imda_technical_test_pytorch_model.pth')\n",
    "sample_catpcha_image_path = r'C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\sampleCaptchas\\input\\input17.jpg'\n",
    "sample_catpcha_image_path_2 = r'C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\torch_training_data\\reserved_unseen\\input100.jpg'\n",
    "\n",
    "ir = torch_ai_model.get_image_information(sample_catpcha_image_path)\n",
    "ir2 = torch_ai_model.get_image_information(sample_catpcha_image_path_2)\n",
    "print(ir, ir2)\n",
    "\n",
    "sample_image = Image.open(sample_catpcha_image_path)\n",
    "display(sample_image)\n",
    "\n",
    "sample_image_2 = Image.open(sample_catpcha_image_path_2)\n",
    "display(sample_image_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a1d186f-5b8a-43ac-bb4a-278416e8db0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6584\n",
      "!!!NEW BEST VAL ACC 1.0\n",
      "\n",
      "Current Best Val Acc: 1.0000 Validation Loss: 0.6584, Validation Accuracy: 1.0000\n",
      "Epoch 2/10, Loss: 0.6584\n",
      "Current Best Val Acc: 1.0000 Validation Loss: 0.6584, Validation Accuracy: 1.0000\n",
      "Epoch 3/10, Loss: 0.6584\n",
      "Current Best Val Acc: 1.0000 Validation Loss: 0.6584, Validation Accuracy: 1.0000\n",
      "Epoch 4/10, Loss: 0.6584\n",
      "Current Best Val Acc: 1.0000 Validation Loss: 0.6584, Validation Accuracy: 1.0000\n",
      "Epoch 5/10, Loss: 0.6584\n",
      "Current Best Val Acc: 1.0000 Validation Loss: 0.6584, Validation Accuracy: 1.0000\n",
      "Epoch 6/10, Loss: 0.6584\n",
      "Current Best Val Acc: 1.0000 Validation Loss: 0.6584, Validation Accuracy: 1.0000\n",
      "Epoch 7/10, Loss: 0.6584\n",
      "Current Best Val Acc: 1.0000 Validation Loss: 0.6584, Validation Accuracy: 1.0000\n",
      "Epoch 8/10, Loss: 0.6584\n",
      "Current Best Val Acc: 1.0000 Validation Loss: 0.6584, Validation Accuracy: 1.0000\n",
      "Epoch 9/10, Loss: 0.6584\n",
      "Current Best Val Acc: 1.0000 Validation Loss: 0.6584, Validation Accuracy: 1.0000\n",
      "Epoch 10/10, Loss: 0.6584\n",
      "Current Best Val Acc: 1.0000 Validation Loss: 0.6584, Validation Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# The Torch Model without O0I1 domain specific discrimination is already capable enough. But,\n",
    "# lets train a O0I1 Discriminator by using the best_model as the pre-trained starting point\n",
    "# Directories\n",
    "O01I_image_dir = r'C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\torch_training_data\\letters_only_O01I\\input'\n",
    "O01I_label_dir = r'C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\torch_training_data\\letters_only_O01I\\output'\n",
    "\n",
    "# Create dataset\n",
    "O01I_dataset = CharacterDataset(O01I_image_dir, O01I_label_dir, transform=transform)\n",
    "\n",
    "# Data loaders\n",
    "batch_size = 1\n",
    "O01I_train_loader = DataLoader(O01I_dataset, batch_size=batch_size, shuffle=True)\n",
    "O01I_validation_loader = O01I_train_loader\n",
    "O01I_criterion = nn.CrossEntropyLoss()\n",
    "O01I_learn_rate = 0.0001\n",
    "O01I_optimizer = optim.Adam(model.parameters(), lr=O01I_learn_rate)\n",
    "scheduler = None\n",
    "\n",
    "# Train\n",
    "O01I_best_model = train_model(best_model, O01I_train_loader, O01I_validation_loader, O01I_criterion, O01I_optimizer, num_epochs=10)\n",
    "\n",
    "# Save\n",
    "O01I_best_model.eval()\n",
    "torch.save(O01I_best_model.state_dict(), 'imda_technical_test_pytorch_O01IDiscriminator_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e42c1331-f4a5-4e6b-932d-2dfa065a60a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'InferredCharacters': '20BHQ'} {'InferredCharacters': 'YMB1Q'}\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD//gA+Q1JFQVRPUjogZ2QtanBlZyB2MS4wICh1c2luZyBJSkcgSlBFRyB2NjIpLCBkZWZhdWx0IHF1YWxpdHkK/9sAQwAIBgYHBgUIBwcHCQkICgwUDQwLCwwZEhMPFB0aHx4dGhwcICQuJyAiLCMcHCg3KSwwMTQ0NB8nOT04MjwuMzQy/9sAQwEJCQkMCwwYDQ0YMiEcITIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIy/8AAEQgAHgA8AwEiAAIRAQMRAf/EAB8AAAEFAQEBAQEBAAAAAAAAAAABAgMEBQYHCAkKC//EALUQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+v/EAB8BAAMBAQEBAQEBAQEAAAAAAAABAgMEBQYHCAkKC//EALURAAIBAgQEAwQHBQQEAAECdwABAgMRBAUhMQYSQVEHYXETIjKBCBRCkaGxwQkjM1LwFWJy0QoWJDThJfEXGBkaJicoKSo1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoKDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uLj5OXm5+jp6vLz9PX29/j5+v/aAAwDAQACEQMRAD8A9xma8hQN50By6r/qT3YD+971G9zNFcNFLd2seEVgXjIzkkf3/b9ap+KZtVg0Y/2NZrcX8s0UcXmyBIoiXH7yQ5yUHcKCx4AHcce/jaXwxr+uQeJbiO8GmWEdy15p8BVQruqrC8ZY7JSxyuWIKsCdoBoA7Sa8B8tGureVSwc+UFH3WB6l8DP+NSLqpaDzVW1J2F/LFx82AM4xt61xV3471/w/bXkPibTLO01G5sLq+0kW0jTxkxRl2gmxg+YgwSy4RgTggjmhovj6+1y98PQPdabrA1CEy3tnpVvKk2n5jGWcmR1KKW2tna2SNoY5WgD0q2tLaWN3kt4nYyyZZkBJ+c0k8VraTW0ojhhHmkFwoXjY3evJF+MbxfC1dbjvdEPiEuxbTjuyMzkfd8zd9z5uv6Vu3XjPXbqz8Q63p0em/wBm+HLx4HguYpFnuniH7/DB8RDa2E4ckjkL0oA7mO5idWZ9TCHe4Cho8ABiB1Hpin292Gh+Z5JCGYb1hZgwDEA5UY6Y6VS0vUl1Tw3pd5FbzJDcxW0yGTbnDbGGcHrg+ldBQByuu2utXGj3C+GLbSrfUGdo4rm7YhYcEguAqHLDHAPGTk5xg8zp3gmWXQrrwrqmkadHYzxOJ7m31GWS4nm3Rv5rs0I3Puw2TkcY27eK9Hs/9S3/AF1k/wDQ2rNlvIrTUZJGVyCWHygZ+7F/hQBwl74N8Sa9bT3PiPULK8vLeyu9P0xrWJ40BliaJp5gFJ3t8oIHyqAcAk8WNP8ADmr3S+EbfUVtLODw4qbbqxaaW4uHjjEflgtEgjicAlx824BRx1r0HT5BJab1BAaRzz15c1Vit1ulM3l2vzyOo32+45DEZJ3c9KAOCj+Hury/An/hCxNaLqfI8x2cRf8AHz5vXbu+7/s9fzqjrHgHXZ/7YstMvfs+m6tqcty9yblkaIzt5U6PCAUnQqFKZ2Mrd+59OitYvtMSSQWrKyM/ywBSCCvufWrnkw+X5HlJ5f8Ac2jb69KAM3TtP/sjwzpWm4x9khtrfHmeZjZsX721d3TrtXPoOlbVZl9Da2lv5628amN0OUQA/eHSo/8AhILT/nnP+Q/xoA//2Q==",
      "image/png": "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",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=60x30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD//gA+Q1JFQVRPUjogZ2QtanBlZyB2MS4wICh1c2luZyBJSkcgSlBFRyB2NjIpLCBkZWZhdWx0IHF1YWxpdHkK/9sAQwAIBgYHBgUIBwcHCQkICgwUDQwLCwwZEhMPFB0aHx4dGhwcICQuJyAiLCMcHCg3KSwwMTQ0NB8nOT04MjwuMzQy/9sAQwEJCQkMCwwYDQ0YMiEcITIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIy/8AAEQgAHgA8AwEiAAIRAQMRAf/EAB8AAAEFAQEBAQEBAAAAAAAAAAABAgMEBQYHCAkKC//EALUQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+v/EAB8BAAMBAQEBAQEBAQEAAAAAAAABAgMEBQYHCAkKC//EALURAAIBAgQEAwQHBQQEAAECdwABAgMRBAUhMQYSQVEHYXETIjKBCBRCkaGxwQkjM1LwFWJy0QoWJDThJfEXGBkaJicoKSo1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoKDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uLj5OXm5+jp6vLz9PX29/j5+v/aAAwDAQACEQMRAD8A9xma8hQN50By6r/qT3YD+971G9zNFcNFLd2seEVgXjIzkkf3/b9azPGN7q2n6PFeaTaC78m7ha7gVS0z24YbxCAQDJ0wCcHkcnArg9a+IepQ6dq3izw9FDd6Ha2Mcdtd30Dobmc3EavsUFSY1VyMkL84OMgGgD0ea8B8tGureVSwc+UFH3WB6l8DP+NSLqpaDzVW1J2F/LFx82AM4xt615fqHxi1YagsNpoK2ixQahHdm8cSkXlrAZGjTy25RW2Zc/eDHAXBNXNF8fX2uXvh6B7rTdYGoQmW9s9Kt5Um0/MYyzkyOpRS21s7WyRtDHK0AelW1pbSxu8lvE7GWTLMgJPzmknitbSa2lEcMI80guFC8bG71xOn+MtYl+Jl34YfTFtdOjs5LuGd4mkml/e7S+FcgIWLAAjPAJxnaK914z126s/EOt6dHpv9m+HLx4HguYpFnuniH7/DB8RDa2E4ckjkL0oA7mO5idWZ9TCHe4Cho8ABiB1Hpin292Gh+Z5JCGYb1hZgwDEA5UY6Y6VS0vUl1Tw3pd5FbzJDcxW0yGTbnDbGGcHrg+ldBQBlwwhiZIrG0AV2CsTg5ViM8Lx0rzJfh3rDfCZvBQm0wakAyGcM4jIFwk3Lbck4OPu+tesWf+pb/rrJ/wChtWbLeRWmoySMrkEsPlAz92L/AAoA4rxl4HuNdvbO60q20+yjSLVI7gIrAyz3MBiEhCR8/MBuY849adp/hzV7pfCNvqK2lnB4cVNt1YtNLcXDxxiPywWiQRxOAS4+bcAo4616Dp8gktN6ggNI5568uaqxW63Smby7X55HUb7fcchiMk7uelAHK2eg+Iv+FlHxOLbTvsJs307y3vJVm8s3Jl83aYcbscbM4/2q57WPAOuz/wBsWWmXv2fTdW1OW5e5NyyNEZ28qdHhAKToVClM7GVu/c+nRWsX2mJJILVlZGf5YApBBX3PrVzyYfL8jyk8v+5tG316UAZunaf/AGR4Z0rTcY+yQ21vjzPMxs2L97au7p12rn0HStqsy+htbS389beNTG6HKIAfvDpUf/CQWn/POf8AIf40Af/Z",
      "image/png": "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",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=60x30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample Inference of O01I discriminator torch trained torch model\n",
    "from TorchInferenceEngine import load_torch_ai_model\n",
    "from PIL import Image\n",
    "\n",
    "torch_ai_model = load_torch_ai_model(model_path = 'imda_technical_test_pytorch_O01IDiscriminator_model.pth')\n",
    "sample_catpcha_image_path = r'C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\sampleCaptchas\\input\\input17.jpg'\n",
    "sample_catpcha_image_path_2 = r'C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\torch_training_data\\reserved_unseen\\input100.jpg'\n",
    "\n",
    "ir = torch_ai_model.get_image_information(sample_catpcha_image_path)\n",
    "ir2 = torch_ai_model.get_image_information(sample_catpcha_image_path_2)\n",
    "print(ir, ir2)\n",
    "\n",
    "sample_image = Image.open(sample_catpcha_image_path)\n",
    "display(sample_image)\n",
    "\n",
    "sample_image_2 = Image.open(sample_catpcha_image_path_2)\n",
    "display(sample_image_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

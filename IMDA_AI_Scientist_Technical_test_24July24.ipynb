{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a3157995-4be5-440f-9227-3506caeab65f",
   "metadata": {},
   "source": [
    "(B) Deliverable  \r\n",
    "1 \tREADME.md \r",
    "2\tPython code (use the following template and feel free to add the necessary methods)\r\n",
    "class Captcha(object):\r\n",
    "    def __init__(self):\r\n",
    "        pass\r\n",
    "\r\n",
    "    def __call__(self, im_path, save_path):\r\n",
    "        \"\"\"\r\n",
    "        Algo for inference\r\n",
    "        args:\r\n",
    "            im_path: .jpg image path to load and to infer\r\n",
    "            save_path: output file path to save the one-line outcome\r\n",
    "        \"\"\"\r\n",
    "        pass\r\n",
    "We would like to learn more about the way you frame the problem and formulate the solution. You may check in the deliverables to your Github or Gitlab and share with us the link.\r\n",
    "b and share with us the link.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60d8ecdb-a25f-4ff9-99e8-5fe866aa20f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "class dataloader(object):\n",
    "    def __init__(self, input_dir, output_dir, training_size = 99):\n",
    "    # Initialize an empty dictionary to store the data\n",
    "        data_dict = {}\n",
    "        data_loaded = 0\n",
    "        # Loop through all files in the input directory\n",
    "        for filename in os.listdir(input_dir):\n",
    "            \n",
    "            if filename.endswith(\".jpg\"):\n",
    "                # Get the full path of the image file\n",
    "                img_path = os.path.join(input_dir, filename)\n",
    "                \n",
    "                # Construct the corresponding txt file name\n",
    "                txt_filename = filename.replace(\".jpg\", \".txt\")\n",
    "                txt_filename = txt_filename.replace(\"input\", \"output\")\n",
    "                txt_path = os.path.join(output_dir, txt_filename)\n",
    "                \n",
    "                if os.path.exists(txt_path):\n",
    "                    with open(txt_path, 'r') as txt_file:\n",
    "                        label = txt_file.read().strip()             \n",
    "                        # Store the image path and label in the dictionary\n",
    "                        data_dict[img_path] = label\n",
    "                        data_loaded += 1\n",
    "                        print(f\"Pairing {filename} with {txt_filename}\")\n",
    "                        if data_loaded == training_size:\n",
    "                            break\n",
    "\n",
    "    \n",
    "        self.data_dict = data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73d08688-5348-449d-89fa-57a2611995df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairing input02B.jpg with output02B.txt\n",
      "Pairing input04B.jpg with output04B.txt\n",
      "Pairing input17B.jpg with output17B.txt\n",
      "Pairing input22B.jpg with output22B.txt\n",
      "Pairing input24B.jpg with output24B.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import langchain\n",
    "from langchain.chains import TransformChain\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import chain\n",
    "import base64\n",
    "import json\n",
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "openai_api_key = \"sk-proj-EdTJfI06sx021wOqwqMUT3BlbkFJQqpltq3qDR6x4yVxElu2\"\n",
    "\n",
    "class llm_model(object):\n",
    "    def __init__(self, vision_prompt, few_shot_prompt, finetune = True, training_data = None):\n",
    "        self.llm = ChatOpenAI(openai_api_key=openai_api_key, temperature=0.0, model=\"gpt-4o\", max_tokens=1024)\n",
    "        self.format_instruction = format_instruction = \"\"\"\n",
    "             Provide your output in the format of a python dict object code {\"InferredCharacters\": \"XXXXX\"}.\n",
    "             Do not provide any other information. \n",
    "             Do not provide the backticks or any characters not related to the dict string such that I can convert to dict object directly by json.load(result)\"\"\"\n",
    "        self.vision_prompt = vision_prompt \n",
    "        if finetune:\n",
    "            self.vision_prompt = self.vision_prompt + few_shot_prompt\n",
    "            for data_path in training_data.data_dict.keys():\n",
    "                encoded_image_data = encode_image(data_path)\n",
    "                fine_tune_data = f\"\"\"```Encoded image data: {encoded_image_data} -> True label: {training_data.data_dict[data_path]}``` \\n\"\"\"\n",
    "                self.vision_prompt = self.vision_prompt + fine_tune_data\n",
    "\n",
    "\n",
    "\n",
    "def encode_image(image_path):\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "            \n",
    "def load_image(inputs: dict) -> dict:\n",
    "    \"\"\"Load image from file and encode it as base64.\"\"\"\n",
    "    image_path = inputs[\"image_path\"]\n",
    "    image_base64 = encode_image(image_path)\n",
    "    return {\"image\": image_base64}\n",
    "\n",
    "load_image_chain = TransformChain(\n",
    "    input_variables=[\"image_path\"],\n",
    "    output_variables=[\"image\"],\n",
    "    transform=load_image\n",
    ")\n",
    "\n",
    "vision_prompt = \"\"\"Given the Captcha image, where \n",
    "1. the font and spacing is the same each time.  \n",
    "2. the background and foreground colors and texture, remain largely the same.\n",
    "3. there is no skew in the structure of the characters.\n",
    "4. the captcha generator, creates strictly 5-character captchas, and each of the characters is either an upper-case character (A-Z) or a numeral (0-9).\n",
    "5. They resemble each other very much where the identify that the texture, nature of the font, spacing of the font, morphological characteristic of the letters and numerals arev very consistent.\n",
    "Infer the image's characters (Only capital letters and numbers)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "few_shot_prompt = \"\"\"Few shot prompting fine tunning: it is very important to take note of the difference between:\n",
    "0 and O  \n",
    "\n",
    "and\n",
    "\n",
    "1 and I\n",
    "\n",
    "Here are some samples describing the challenging characters for you to tell the difference between 0, O, 1 and I are provided delimited by triple backticks: \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "finetune_input_dir = r\"C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\fine-tune-data\\input\"\n",
    "finetune_output_dir = r\"C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\fine-tune-data\\output\"\n",
    "training_data = dataloader(input_dir = finetune_input_dir, output_dir = finetune_output_dir)\n",
    "llm_agent = llm_model(vision_prompt, few_shot_prompt, finetune = False, training_data = training_data)\n",
    "\n",
    "@chain\n",
    "def image_model(inputs: dict) -> str:\n",
    "    \"\"\"Invoke model with image and prompt.\"\"\"\n",
    "    model = llm_agent.llm\n",
    "    # print(\"Final vision prompt\\n\", inputs[\"prompt\"])\n",
    "    msg = model.invoke(\n",
    "             [SystemMessage(content=llm_agent.format_instruction),\n",
    "              HumanMessage(\n",
    "             content=[\n",
    "             {\"type\": \"text\", \"text\": inputs[\"prompt\"]},\n",
    "             {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{inputs['image']}\"}},\n",
    "             ])]\n",
    "             )\n",
    "    return msg.content\n",
    "\n",
    "@tool\n",
    "def convert_output_to_dict(llm_output:str) -> dict:\n",
    "    \"\"\"Convert the output of the LLM to a simple dict with only the predicted output as the key\"\"\"\n",
    "    try:\n",
    "        response_dict = json.loads(llm_output)\n",
    "    except json.JSONDecodeError:\n",
    "        response_dict = {\"error\": \"Invalid JSON response\"}\n",
    "    return response_dict\n",
    "    \n",
    "\n",
    "\n",
    "'''def get_image_information(image_path: str, llm_model, finetune = False, training_data = None) -> dict:\n",
    "    vision_prompt = \"\"\"Given the Captcha image, where \n",
    "    1. the number of characters remains the same each time.  \n",
    "    2. the font and spacing is the same each time.  \n",
    "    3. the background and foreground colors and texture, remain largely the same.\n",
    "    4. there is no skew in the structure of the characters.\n",
    "    5. the captcha generator, creates strictly 5-character captchas, and each of the characters is either an upper-case character (A-Z) or a numeral (0-9).\n",
    "    6. They resemble each other very much where the identify that the texture, nature of the font, spacing of the font, morphological characteristic of the letters and numerals arev very consistent.\n",
    "    Infer the image's characters (Only capital letters and numbers)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if finetune:\n",
    "        few_shot_prompt = \"\"\"Given the data, it is very important to take note of the difference between:\n",
    "        ```0 and O```  \n",
    "        and\n",
    "        ```1 and I```\n",
    "        In our dataset, their difference are consistent and you must fine-tune yourself to adapt to the font format\n",
    "        A list of sample data describing the difference between 0, O, 1 and I are provided to allow you to fine-tune your performance for the given task: \n",
    "        \"\"\"\n",
    "        vision_prompt = vision_prompt + few_shot_prompt\n",
    "        for data_path in training_data.data_dict.keys():\n",
    "            encoded_image_data = encode_image(data_path)\n",
    "            fine_tune_data = f\"\"\"Image data: {encoded_image_data} -> True label: {training_data.data_dict[data_path]} \\n\\n\"\"\"\n",
    "            vision_prompt = vision_prompt + fine_tune_data\n",
    "    \n",
    "            \n",
    "    vision_chain = load_image_chain | image_model | convert_output_to_dict\n",
    "    return vision_chain.invoke({'image_path': f'{image_path}', \n",
    "                               'prompt': vision_prompt})'''\n",
    "\n",
    "def get_image_information(image_path: str, llm_model) -> dict:\n",
    "    vision_prompt = llm_model.vision_prompt\n",
    "    vision_chain = load_image_chain | image_model | convert_output_to_dict\n",
    "    return vision_chain.invoke({'image_path': f'{image_path}', \n",
    "                               'prompt': vision_prompt})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5accc6b-2eee-4efb-878d-b8a2e6bed2a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Sample inferencing\\nsample_image = \"C:/Users/guang/OneDrive/Desktop/IMDA/sampleCaptchas/input/input00.jpg\"\\ntraining_data = dataloader(input_dir, output_dir, training_size = 3) # Select an integer between 1 to 25 to set the amount of data used to fine tune \\nresult = get_image_information(sample_image, llm_agent, finetune = True, training_data = training_data)\\nprint(result)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Sample inferencing\n",
    "sample_image = \"C:/Users/guang/OneDrive/Desktop/IMDA/sampleCaptchas/input/input00.jpg\"\n",
    "training_data = dataloader(input_dir, output_dir, training_size = 3) # Select an integer between 1 to 25 to set the amount of data used to fine tune \n",
    "result = get_image_information(sample_image, llm_agent, finetune = True, training_data = training_data)\n",
    "print(result)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62776d59-5537-4322-acc2-ec9b507fe2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Captcha(object):\n",
    "    def __init__(self, finetune = False, llm_agent = None):\n",
    "        self.finetune = finetune\n",
    "        self.llm_agent = llm_agent\n",
    "        \n",
    "\n",
    "    def __call__(self, im_path, save_path):\n",
    "        \"\"\"\n",
    "        Algo for inference\n",
    "        args:\n",
    "            im_path: .jpg image path to load and to infer\n",
    "            save_path: output file path to save the one-line outcome\n",
    "        \"\"\"\n",
    "        result = get_image_information(im_path, self.llm_agent)\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "590508a9-f9b8-49ac-a6c7-ac69e6fe176d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'InferredCharacters': 'EGYK4'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# declare inferencer and sample inferencing\n",
    "sample_image = \"C:/Users/guang/OneDrive/Desktop/IMDA/sampleCaptchas/input/input00.jpg\"\n",
    "\n",
    "\n",
    "captcha_inferencer = Captcha(llm_agent = llm_agent)\n",
    "captcha_inferencer(sample_image, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f9715e9-0ce7-4fdd-be9b-69d1a17eb4b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairing input00.jpg with output00.txt\n",
      "Pairing input01.jpg with output01.txt\n",
      "Pairing input02.jpg with output02.txt\n",
      "Pairing input03.jpg with output03.txt\n",
      "Pairing input04.jpg with output04.txt\n",
      "Pairing input05.jpg with output05.txt\n",
      "Pairing input06.jpg with output06.txt\n",
      "Pairing input07.jpg with output07.txt\n",
      "Pairing input08.jpg with output08.txt\n",
      "Pairing input09.jpg with output09.txt\n",
      "Pairing input10.jpg with output10.txt\n",
      "Pairing input11.jpg with output11.txt\n",
      "Pairing input12.jpg with output12.txt\n",
      "Pairing input13.jpg with output13.txt\n",
      "Pairing input14.jpg with output14.txt\n",
      "Pairing input15.jpg with output15.txt\n",
      "Pairing input16.jpg with output16.txt\n",
      "Pairing input17.jpg with output17.txt\n",
      "Pairing input18.jpg with output18.txt\n",
      "Pairing input19.jpg with output19.txt\n",
      "Pairing input20.jpg with output20.txt\n",
      "Pairing input22.jpg with output22.txt\n",
      "Pairing input23.jpg with output23.txt\n",
      "Pairing input24.jpg with output24.txt\n",
      "Predict result: EGYK4 versus True Label: EGYK4\n",
      "Predict result: GRC35 versus True Label: GRC35\n",
      "Predict result: 605W1 versus True Label: 6O5W1\n",
      "incorrect! Predicting C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\sampleCaptchas\\input\\input02.jpg\n",
      "Predict result: J627C versus True Label: J627C\n",
      "Predict result: VL12C versus True Label: VLI2C\n",
      "incorrect! Predicting C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\sampleCaptchas\\input\\input04.jpg\n",
      "Predict result: 01R7Q versus True Label: O1R7Q\n",
      "incorrect! Predicting C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\sampleCaptchas\\input\\input05.jpg\n",
      "Predict result: OYTAD versus True Label: OYTAD\n",
      "Predict result: ZRMQU versus True Label: ZRMQU\n",
      "Predict result: N9DQS versus True Label: N9DQS\n",
      "Predict result: ZGJS3 versus True Label: ZGJS3\n",
      "Predict result: GZMBA versus True Label: GZMBA\n",
      "Predict result: J14DM versus True Label: J14DM\n",
      "Predict result: PQ9AE versus True Label: PQ9AE\n",
      "Predict result: VWZDO versus True Label: VWZDO\n",
      "Predict result: WGST7 versus True Label: WGST7\n",
      "Predict result: XKMS2 versus True Label: XKMS2\n",
      "Predict result: 1D2KB versus True Label: 1D2KB\n",
      "Predict result: 20BHQ versus True Label: 20BHQ\n",
      "Predict result: OAHOV versus True Label: OAH0V\n",
      "incorrect! Predicting C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\sampleCaptchas\\input\\input18.jpg\n",
      "Predict result: 518VE versus True Label: 5I8VE\n",
      "incorrect! Predicting C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\sampleCaptchas\\input\\input19.jpg\n",
      "Predict result: Z97ME versus True Label: Z97ME\n",
      "Predict result: HCE91 versus True Label: HCE91\n",
      "Predict result: WELXV versus True Label: WELXV\n",
      "Predict result: UHVFO versus True Label: UHVFO\n",
      "Final remarks: corrects 19 out of 24 attempts. accuracy of 0.79\n"
     ]
    }
   ],
   "source": [
    "input_dir = r\"C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\sampleCaptchas\\input\"\n",
    "output_dir = r\"C:\\Users\\guang\\OneDrive\\Desktop\\IMDA\\sampleCaptchas\\output\"\n",
    "\n",
    "inference_data = dataloader(input_dir, output_dir)\n",
    "\n",
    "corrects = 0\n",
    "attempts = 0\n",
    "for data_path in inference_data.data_dict:\n",
    "    true_label = inference_data.data_dict[data_path]\n",
    "    inferred_output = captcha_inferencer(data_path, None)\n",
    "    predict = inferred_output['InferredCharacters']\n",
    "    print(f\"Predict result: {predict} versus True Label: {true_label}\")\n",
    "    if predict == true_label:\n",
    "        corrects += 1\n",
    "    else:\n",
    "        print(\"incorrect! Predicting\", data_path)\n",
    "    attempts += 1\n",
    "\n",
    "print(f\"Final remarks: corrects {corrects} out of {attempts} attempts. accuracy of {corrects/attempts:.2f}\")\n",
    "\n",
    "\n",
    "# Common errors, mistaken O as 0, I mistake as 1, mistake 0 as O, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce7d06d-91d8-4b4e-af98-493567af64aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f14a5a-6314-4f6b-8cab-777d2b655479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
